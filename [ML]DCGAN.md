# DCGAN을 알아보자

## 1. GAN의 한계

GAN은 분명히 혁신적인 알고리즘 이었지만 한계 또한 존재했다. 
- 고해상도 이미지 생성 불가

- 학습 불안정
이와 같은 문제는 Minimax problem을 해결하는 네트워크 구조와 Fully connected network를 사용하는 GAN 자체의 구조에서 기인한 것이었다. 

오늘 알아볼 DCGAN은 FCN을 사용하는 네트워크 구조를 바꾸어 이와 같은 문제점을 해결했다. 

## 2. GAN과의 차이점

 사실 GAN과의 차이는 별로 없다. GAN의 Fully-connected network를 Deep convolution network로 대체했을 뿐이다. 

 하지만 이와 같은 차이점이 다음과 같은 결과를 이끌어 낼 수 있었다

- Scene을 이해하고 기존 GAN보다 고해상도의 이미지 생성

-  기존 GAN에 비해 안정된 학습 가능

- DCGAN의 특정 컨벌루션 필터가 특정 물체를 학습한다는 것 확인

- G에서 memorization이 일어난 것이 아니라는 것을 확인

- G의 입력으로 들어가는 벡터에 대한 산술 연산이 가능한 점을 가지고 sementic하게 출력 결과를 조절 가능

## 3. 모델 구조

DCGAN은 앞에서 보다시피 FCN 부분을 DCN으로 교체했을 뿐이라 loss 함수는 기존과 동일하다. 다만 단순히 FCN으로의 교체만 일어난 것이 아니라 연구팀이 수많은 실험을 통해 최적의 네트워크 구조를 만들었다. 

원 논문을 찾아보면 연구팀이 사실상 매뉴얼에 가깝게 모델 구조를 정리한 것을 볼 수 있을 것이다. 

[그림 1]

주요한 모델 구조는 다음과 같다. 

- D에서는 일반적인 CNN과 같이 Strided Convolution을 사용한다. 

- G에서는 업샘플링을 위해 Fractional Strided Convolution을 사용한다.(tensorflow의 tf.layers.conv2d_transpose)

- G와 D 모두에서 Batch Normalization을 적용하지만 불안정 및 발산 문제로 인해 D 입력 레이어와 G 출력 레이어에서는 사용하지 않는다. 

- G에서는 ReLU를 사용하고 마지막 레이어에서만 tanh를 사용

- D에서는 모두 Leaky ReLU를 사용한다.


> Fractional Strided Convolution이란?"""  
> 
> 간단하게 설명하자면 기존 합성곱 연산처럼 필터를 거치며 다운샘플링되는것이 아니라 연산을 거치면 업샘플링되어 사이즈가 늘어나는 합성곱 연산이다.  
>  텐서플로우에서는 tf.layers.conv2d_transpose라는 이름으로 구현되어 있으며 원 논문에서 언급한 deconvolution이란 단어는 잘못된 표현이다.
>
>[그림 2]  
> .

## 4. DCGAN의 결과

앞서 언급했듯이 DCGAN은 유의미한 성과를 이끌어 낼 수 있었다. 그 중에서 

- D의 컨벌루션 필터가 특정 물체를 학습한다는 것 확인

- G에서 memorization이 일어난 것이 아니라는 것을 확인

- G의 입력으로 들어가는 z 벡터에 대한 산술 연산이 가능한 점을 가지고 sementic하게 출력 결과를 조절 가능

이 세가지 목표에 대해서 저자들은 실험을 진행했다. 

### 4.1 G의 학습 확인
G가 단순히 입력 데이터를 외워서 출력하는것이 아니라 실제로 데이터를 학습했다는것을 확인하기 위해 저자들은 두가지의 실험을 진행했다. 

- walking in the latent space
- 기억의 망각

#### a. walking in the latent space
저자들은 G가 이미지를 외우는것이 아닌 학습한다는것을 증명하기 위해 이 실험을 수행했다.   
z 벡터가 변할때 z 벡터에 따라 1:1 매칭이 되어 memorization 현상이 일어난다면 급작스러운 변화가 일어난다는 것을 알고 입력의 두개의 z 벡터를 뽑아 그 사이에서 9번의 보간을 수행해며 G가 z 벡터에 따라 연속적으로 변화하는것을 확인했다. 

[그림 3]

#### b. 기억의 망각
G가 학습을 했다면 특정 사물을 인식하는 필터를 가지고 있다는 가정 하에 특정 물체에 대한 필터의 내용을 지운 다음 이미지를 생성했고 지운 물체가 생성된 이미지에서 사라진 모습을 볼 수 있었다. 

[그림 4]

### 4.2 D 필터의 반응 확인

D 필터들이 실제로 이미지에 반응하는지 확인하기 위해 D의 필터들을 시각화 해서 실제로 물체에 반응하는것을 확인했다. 

[그림 5]

### 4.3 z 벡터에 대한 연산

G는 z 벡터에 따라 이미지를 출력하는 구조로 되어 있다. 따라서 한 z벡터가 만약 웃는 남자에 대한 입력이라면 그 z를 입력으로 삼은 G의 출력은 항상 웃는 남자가 있는 것이다. 

그런데 여기서 그치지 않고 입력하는 z 벡터간의 산술 연산으로 semantic하게 출력 결과를 조정할수 있다. 

다음은 웃는 여자 - 여자 + 남자를 했을때 웃는 남자를 생성하는 예시이다. 

[그림 6]

이처럼 z벡터간의 산술 연산이 semantic한 변화를 일으킬수 있는 이유는 특징에 대한 백터들을 빼고 더함으로써 입력 벡터가 달라지며 필터의 반응이 달라져 이러한 변화를 일으키는 것이다. 

## 5. 앞으로의 주절주절

DCGAN이 모델 구조를 개선했다면 GAN의 근본적인 문제인 loss의 불안정성을 해결한 Wassertein GAN도 보면 좋을것같으며 D를 AE로 바꾼 EBGAN또한 앞으로 봐야할 것 같다.