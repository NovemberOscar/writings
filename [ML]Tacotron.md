# Tacotron

## 기존 음성 생성 기술의 한계

현대에 나온 많은 TTS(Text to Speech) 기술은 매우 복잡하다. 대부분 많은 부분으로 구성되지만 이런 복잡한 구조가 오히려 오류를 누적시키기 때문에 상당한 기술적 노력이 필요했다. 그러나 딥러닝 기술을 사용한 종단간(end-to-end) 모델은 인간이 최소한으로 개입하는 <텍스트-소리> 쌍으로 학습하는 방식이기 때문에 많은 장점을 가지고 있다.

논문에서 기술된 종단간 모델의 장점은 다음과 같다.

- 휴리스틱과 신뢰성 없는 설계를 포함한 난이도 높은 피처 엔지니어링을 사용할 필요가 없다.
- 정서, 말하는 사람의 특성이나 언어적인 차이를 비롯해 다양한 속성을 쉽게 조절해 컨디셔닝이 가능하다.
- 새 데이터에 적응이 쉽다
- 단일 모델이기 때문에 여러 요소의 오류가 복합적으로 작용하는 다단계 모델보다 성능이 강력하다.

이처럼 종단간 모델은 실제 음성 데이터를 통해 뛰어난 성능을 발휘하게 훈련시킬 수 있다.

하지만 높게 압축된 정보만을 가진 텍스트에서 말투, 강세, 빠르기와 같이 수많은 부수적인 정보를 가진 음성으로 만들기 위한 TTS 기술은 대규모의 디코딩 작업이기 때문에 종단간 모델에서 해결하기 어려운 문제였고 또한 TTS는 출력이 입력보다 길며 연속적인 시퀀스 데이터기 때문에 오류가 누적되는 문제 또한 가지고 있었다. 

## 타코트론의 소개
이 논문에서는 어텐션 패러다임을 활용하는 Seq2Seq 기반의 종단간 TTS 모델인 Tacotron을 소개한다. (기본적인 seq2seq 모델의 성능을 개선하기 위해 몇가지 기술을 도입했다.) 

타코트론은 문자(Characrter)를 입력으로 받아 저수준 스팩트로그램을 출력한다. 

기존의 모델과 다르게 타코트론은 <문자-음성> 쌍을 받아 바닥부터 모델을 훈련시키며 단어 단위로 훈련시키지 않고 음소 단위로 훈련시키기 때문에 충분한 데이터가 확보되었다면 음소를 조합해 다양한 발음을 만들어 낼 수 있다. 이는 타코트론이 매우 자연스러운 발음을 한다는것으로 확인할 수 있다.

## 타코트론의 구조

타코트론은 스팩트로그램을 음성으로 바꾸는 후처리 네트워크를 제외하고 seq2seq와 같이 두가지 구조로 구성되어 있다. 

글자 임베딩을 수행하는 Encoder, 글자에서 스팩트로그램을 생성하는 Attention-Based Decoder로 구성되어 있다.
### CBHG module
CBHG 모듈은 Convolution Bank, Highway net, Gated recurrent nn의 줄임말이다.  
CBHG 모델은 시퀀스에서 인코딩된 표현을 추출하기 위한 모듈이다.

CBHG 모듈의 진행은 다음과 같다.
1. 입력으로 들어온 시퀀스는 K 개의 1-D 컨벌루션 필터를 가진 컨벌루션 뱅크를 통과한다. 이 단계는 로컬 및 문맥적 정보를 명시적으로 모델링한다.
2. 컨벌루션된 결과물은 스택되고 시간에 따라 맥스 풀링되어 로컬 불변량을 증가시킨다
3. 원래 시간 해상도를 유지하기 위해 스트라이드 1로 컨벌루션한다.
4. 상기 과정을 통하여 처리된 시퀀스를 고정폭 1-D 컨벌루션으로 프로젝션한다. 
5. 4 번의 출력에 residual 연결을 통해 원본 입력 시퀀스를 포함시킨다.
6. 5번의 결과물을 고수준 피처 추출을 위한 하이웨이 네트워크에 입력으로 제공한다.
7. 마지막으로 앞뒤 문맥을 다 활용할 수 있는 양방향 GRU(Gated Recurrent Unit) RNN을 쌓아 시퀀스 피처를 추출한다. (여기서는 임베딩된 문자)

### Encoder
인코더의 목표는 텍스트의 시퀀스 표현을 강력하게 뽑아내는 것이다.

인코더의 모델은 다음과 같이 구성되어 있다. 
1. 인코더의 입력으로 들어온 문자의 연속을 원-핫 인코딩하여 연속적인 벡터로 임베딩한다.
2. 각각 임베딩된 벡터에 대해 pre-net을 통과시킨다(이 pre-net의 dropout이 일반화와 피팅을 도와준다.)
3. CBHG 모듈이 2번의 출력을 어텐션 모듈에서 사용할 최종 출력으로 변환한다.

### Decoder
우리는 콘텐츠 기반의 tanh 어텐션 디코더를 사용한다. 앞의 그림에서 볼 수 있듯이 디코더 셀의 입력으로는 어텐션 RNN의 출력과 인코더의 컨텍스트 벡터를 연관시켜 구성한다.

디코더는 츨력으로 합성한 음성에 대응되는 스펙트로그램을 만들어 낸다. 

글자 하나가 여러 음성에 대응되는 경우를 고려해 디코더는 한 문자에 대해 출력으로 다수의 스팩트로그램 프레임을 예측하여 다음 시간으로 넘긴다. 이떄 r개를 출력하면 r로 전체 시간이 나누어져 자원 절감 효과가 있다.






#### Attention

>>>
디코더의 목표를 정하는 것은 설계상의 중요한 목표이다. 디코더로 바로 스팩트로그램을 예측할 수도 있겠지만 음성-텍스트간 정렬을 학습하는 목적에 맞지 않고 이것이 seq2seq를 사용하는 이유이다. <== 디코더로만 하면 어텐션 필요 없으니까 어텐션 사용 이유!!!!! 아 시발 해결

우리는 파형 합성과 seq2seq 디코딩은 목표가 다르다.
이 타겟 중 seq2seq의 출력은 데이터를 충분히 제공할수록 고도로 압축될 수 있다.
우리는 80대역 스펙트로그램 대신 셉스트럼같은 더 간단한 출력을 만들수도 있다.
>>>