# Tacotron

## 기존 음성 생성 기술의 한계

현대에 나온 많은 TTS(Text to Speech) 기술은 매우 복잡하다. 대부분 많은 부분으로 구성되지만 이런 복잡한 구조가 오히려 오류를 누적시키기 때문에 상당한 기술적 노력이 필요했다. 그러나 딥러닝 기술을 사용한 종단간(end-to-end) 모델은 인간이 최소한으로 개입하는 <텍스트-소리> 쌍으로 학습하는 방식이기 때문에 많은 장점을 가지고 있다.

논문에서 기술된 종단간 모델의 장점은 다음과 같다.

- 휴리스틱과 신뢰성 없는 설계를 포함한 난이도 높은 피처 엔지니어링을 사용할 필요가 없다.
- 정서, 말하는 사람의 특성이나 언어적인 차이를 비롯해 다양한 속성을 쉽게 조절해 컨디셔닝이 가능하다.
- 새 데이터에 적응이 쉽다
- 단일 모델이기 때문에 여러 요소의 오류가 복합적으로 작용하는 다단계 모델보다 성능이 강력하다.

이처럼 종단간 모델은 실제 음성 데이터를 통해 뛰어난 성능을 발휘하게 훈련시킬 수 있다.

하지만 높게 압축된 정보만을 가진 텍스트에서 말투, 강세, 빠르기와 같이 수많은 부수적인 정보를 가진 음성으로 만들기 위한 TTS 기술은 대규모의 디코딩 작업이기 때문에 종단간 모델에서 해결하기 어려운 문제였고 또한 TTS는 출력이 입력보다 길며 연속적인 시퀀스 데이터기 때문에 오류가 누적되는 문제 또한 가지고 있었다. 

## 타코트론의 소개
이 논문에서는 어텐션 패러다임을 활용하는 Seq2Seq 기반의 종단간 TTS 모델인 Tacotron을 소개한다. (기본적인 seq2seq 모델의 성능을 개선하기 위해 몇가지 기술을 도입했다.) 

타코트론은 문자(Characrter)를 입력으로 받아 저수준 스팩트로그램을 출력한다. 

기존의 모델과 다르게 타코트론은 <문자-음성> 쌍을 받아 바닥부터 모델을 훈련시키며 단어 단위로 훈련시키지 않고 음소 단위로 훈련시키기 때문에 충분한 데이터가 확보되었다면 음소를 조합해 다양한 발음을 만들어 낼 수 있다. 이는 타코트론이 매우 자연스러운 발음을 한다는것으로 확인할 수 있다.

## 타코트론의 구조

타코트론은 스팩트로그램을 음성으로 바꾸는 후처리 네트워크를 제외하고 seq2seq와 같이 두가지 구조로 구성되어 있다. 

글자 임베딩을 수행하는 Encoder, 글자에서 스팩트로그램을 생성하는 Attention-Based Decoder로 구성되어 있다.
### CBHG module
CBHG 모듈은 Convolution Bank, Highway net, Gated recurrent nn의 줄임말이다.CBHG 모델은 시퀀스에서 인코딩된 표현을 추출하기 위한 모듈이다.

CBHG 모듈의 진행은 다음과 같다.
1. 입력으로 들어온 시퀀스는 K 개의 1-D 컨벌루션 필터를 가진 컨벌루션 뱅크를 통과한다. 이 단계는 로컬 및 문맥적 정보를 명시적으로 모델링한다.
2. 컨벌루션된 결과물은 스택되고 시간에 따라 맥스 풀링되어 로컬 불변량을 증가시킨다
3. 원래 시간 해상도를 유지하기 위해 스트라이드 1로 컨벌루션한다.
4. 상기 과정을 통하여 처리된 시퀀스를 고정폭 1-D 컨벌루션으로 프로젝션한다. 
5. 4 번의 출력에 residual 연결을 통해 원본 입력 시퀀스를 포함시킨다.
6. 5번의 결과물을 고수준 피처 추출을 위한 하이웨이 네트워크에 입력으로 제공한다.
7. 마지막으로 앞뒤 문맥을 다 활용할 수 있는 양방향 GRU(Gated Recurrent Unit) RNN을 쌓아 시계열 피처를 추출한다. (여기서는 임베딩된 문자)

### Encoder

### Decoder

#### Attention


