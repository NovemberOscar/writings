# Tacotron

## 기존 음성 생성 기술의 한계

현대에 나온 많은 TTS(Text to Speech) 기술은 매우 복잡하다. 대부분 많은 부분으로 구성되지만 이런 복잡한 구조가 오히려 오류를 누적시키기 때문에 상당한 기술적 노력이 필요했다. 그러나 딥러닝 기술을 사용한 종단간(end-to-end) 모델은 인간이 최소한으로 개입하는 <텍스트-소리> 쌍으로 학습하는 방식이기 때문에 많은 장점을 가지고 있다.

논문에서 기술된 종단간 모델의 장점은 다음과 같다.

- 휴리스틱과 신뢰성 없는 설계를 포함한 난이도 높은 피처 엔지니어링을 사용할 필요가 없다.
- 정서, 말하는 사람의 특성이나 언어적인 차이를 비롯해 다양한 속성을 쉽게 조절해 컨디셔닝이 가능하다.
- 새 데이터에 적응이 쉽다
- 단일 모델이기 때문에 여러 요소의 오류가 복합적으로 작용하는 다단계 모델보다 성능이 강력하다.

이처럼 종단간 모델은 실제 음성 데이터를 통해 뛰어난 성능을 발휘하게 훈련시킬 수 있다.

하지만 높게 압축된 정보만을 가진 텍스트에서 말투, 강세, 빠르기와 같이 수많은 부수적인 정보를 가진 음성으로 만들기 위한 TTS 기술은 대규모의 디코딩 작업이기 때문에 종단간 모델에서 해결하기 어려운 문제였고 또한 TTS는 출력이 입력보다 길며 연속적인 시퀀스 데이터기 때문에 오류가 누적되는 문제 또한 가지고 있었다. 

## 타코트론의 소개
이 논문에서는 어텐션 패러다임을 활용하는 Seq2Seq 기반의 종단간 TTS 모델인 Tacotron을 소개한다. (기본적인 seq2seq 모델의 성능을 개선하기 위해 몇가지 기술을 도입했다.) 

타코트론은 문자(Characrter)를 입력으로 받아 저수준 스팩트로그램을 출력한다. 

기존의 모델과 다르게 타코트론은 <문자-음성> 쌍을 받아 바닥부터 모델을 훈련시키며 단어 단위로 훈련시키지 않고 음소 단위로 훈련시키기 때문에 충분한 데이터가 확보되었다면 음소를 조합해 다양한 발음을 만들어 낼 수 있다. 이는 타코트론이 매우 자연스러운 발음을 한다는것으로 확인할 수 있다.

## 타코트론의 구조

타코트론은 스팩트로그램을 음성으로 바꾸는 후처리 네트워크를 제외하고 seq2seq와 같이 두가지 구조로 구성되어 있다. 

글자 임베딩을 수행하는 Encoder, 글자에서 스팩트로그램을 생성하는 Attention-Based Decoder로 구성되어 있다.
### CBHG module

### Decoder
#### Attention

### Encoder


